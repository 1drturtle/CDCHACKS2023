{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "np.random.seed(455)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_1072\\313727318.py:1: DtypeWarning: Columns (10,11,12,18,35,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(\"data/NautralSciences_Dataset.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 937972 entries, 0 to 937971\n",
      "Data columns (total 39 columns):\n",
      " #   Column                      Non-Null Count   Dtype  \n",
      "---  ------                      --------------   -----  \n",
      " 0   OBJECTID                    937972 non-null  int64  \n",
      " 1   FOD_ID                      937972 non-null  int64  \n",
      " 2   FPA_ID                      937972 non-null  object \n",
      " 3   SOURCE_SYSTEM_TYPE          937972 non-null  object \n",
      " 4   SOURCE_SYSTEM               937972 non-null  object \n",
      " 5   NWCG_REPORTING_AGENCY       937972 non-null  object \n",
      " 6   NWCG_REPORTING_UNIT_ID      937972 non-null  object \n",
      " 7   NWCG_REPORTING_UNIT_NAME    937972 non-null  object \n",
      " 8   SOURCE_REPORTING_UNIT       937972 non-null  object \n",
      " 9   SOURCE_REPORTING_UNIT_NAME  937972 non-null  object \n",
      " 10  LOCAL_FIRE_REPORT_ID        212814 non-null  object \n",
      " 11  LOCAL_INCIDENT_ID           446908 non-null  object \n",
      " 12  FIRE_CODE                   196422 non-null  object \n",
      " 13  FIRE_NAME                   412222 non-null  object \n",
      " 14  ICS_209_INCIDENT_NUMBER     16728 non-null   object \n",
      " 15  ICS_209_NAME                16727 non-null   object \n",
      " 16  MTBS_ID                     5742 non-null    object \n",
      " 17  MTBS_FIRE_NAME              5742 non-null    object \n",
      " 18  COMPLEX_NAME                3044 non-null    object \n",
      " 19  FIRE_YEAR                   937972 non-null  int64  \n",
      " 20  DISCOVERY_DATE              937972 non-null  float64\n",
      " 21  DISCOVERY_DOY               937972 non-null  int64  \n",
      " 22  DISCOVERY_TIME              410684 non-null  float64\n",
      " 23  STAT_CAUSE_CODE             937972 non-null  int64  \n",
      " 24  STAT_CAUSE_DESCR            937972 non-null  object \n",
      " 25  CONT_DATE                   395040 non-null  float64\n",
      " 26  CONT_DOY                    395040 non-null  float64\n",
      " 27  CONT_TIME                   368586 non-null  float64\n",
      " 28  FIRE_SIZE                   937972 non-null  float64\n",
      " 29  FIRE_SIZE_CLASS             937972 non-null  object \n",
      " 30  LATITUDE                    937972 non-null  float64\n",
      " 31  LONGITUDE                   937972 non-null  float64\n",
      " 32  OWNER_CODE                  937972 non-null  int64  \n",
      " 33  OWNER_DESCR                 937972 non-null  object \n",
      " 34  STATE                       937972 non-null  object \n",
      " 35  COUNTY                      617750 non-null  object \n",
      " 36  FIPS_CODE                   617750 non-null  float64\n",
      " 37  FIPS_NAME                   617750 non-null  object \n",
      " 38  Shape                       0 non-null       float64\n",
      "dtypes: float64(10), int64(6), object(23)\n",
      "memory usage: 279.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/NautralSciences_Dataset.csv\")\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#state to num\n",
    "states = [ 'AK', 'AL', 'AR', 'AZ', 'CA', 'CO', 'CT', 'DC', 'DE', 'FL', 'GA',\n",
    "           'HI', 'IA', 'ID', 'IL', 'IN', 'KS', 'KY', 'LA', 'MA', 'MD', 'ME',\n",
    "           'MI', 'MN', 'MO', 'MS', 'MT', 'NC', 'ND', 'NE', 'NH', 'NJ', 'NM',\n",
    "           'NV', 'NY', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX',\n",
    "           'UT', 'VA', 'VT', 'WA', 'WI', 'WV', 'WY', 'DC', 'PR']\n",
    "\n",
    "st_dict = {i: s for s, i in enumerate(states)}\n",
    "\n",
    "data[\"STATE_CODE\"] = data[\"STATE\"].replace(st_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = ['A','B','C','D','E','F','G']\n",
    "\n",
    "size_dict = {i: s for s, i in enumerate(sizes)}\n",
    "\n",
    "data[\"FIRE_SIZE_CLASS_NUM\"] = data[\"FIRE_SIZE_CLASS\"].replace(size_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gathering data\n",
    "training_data_input = data[[\"LATITUDE\",\"LONGITUDE\",\"STAT_CAUSE_CODE\",\"STATE_CODE\",\"DISCOVERY_DOY\"]].to_numpy()\n",
    "#training_data_input = data[[\"STAT_CAUSE_CODE\",\"STATE_CODE\",\"DISCOVERY_DOY\"]].to_numpy()\n",
    "training_data_label = data[['FIRE_SIZE_CLASS_NUM']].to_numpy()\n",
    "size = training_data_input.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data!\n",
    "# i am doing a 60/20/20 split\n",
    "a = int(size*.60)\n",
    "b = int(size*.80)\n",
    "\n",
    "#train\n",
    "train_input = training_data_input[0:a-2]\n",
    "train_labels =training_data_label[0:a-2]\n",
    "\n",
    "#test \n",
    "test_input = training_data_input[a-1:b-2]\n",
    "test_labels =training_data_label[a-1:b-2]\n",
    "\n",
    "#validate\n",
    "val_input = training_data_input[b-1:]\n",
    "val_labels =training_data_label[b-1:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IF YOU DONT WANT YOUR COMPUTER TO CRASH AND USE ALL ITS CPU AND RAM DONT TRAIN THE MODEL\n",
    " \n",
    "If you are really that curious email alpagar@unc.edu and I'll send the downloaded model and a notebook for a demo but bro its 17GB\n",
    "\n",
    "Thank you :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "562781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=-1)]: Done 152 tasks      | elapsed:   55.1s\n",
      "[Parallel(n_jobs=-1)]: Done 402 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 752 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:  5.6min finished\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Model\n",
    "print(len(train_input))\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 69, verbose=True, n_jobs=-1)\n",
    "rf.fit(train_input, np.ravel(train_labels));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tree_model_final.joblib']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(rf, \"tree_model_final.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = joblib.load(\"tree_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 152 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=24)]: Done 402 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=24)]: Done 752 tasks      | elapsed:    3.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for split train\n",
      "  MSE: 0.06854369097322503\n",
      "  R2:  0.9046558245726173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=24)]: Done 1000 out of 1000 | elapsed:    5.2s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "predictions = rf.predict(train_input)\n",
    "print(\"Results for split train\")\n",
    "print(f\"  MSE: {mean_squared_error(train_labels, predictions)}\")\n",
    "print(f\"  R2:  {r2_score(train_labels, predictions)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 152 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=24)]: Done 402 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=24)]: Done 752 tasks      | elapsed:    1.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for split test\n",
      "  MSE: 0.5226009611168896\n",
      "  R2:  0.16943676320461154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=24)]: Done 1000 out of 1000 | elapsed:    1.7s finished\n"
     ]
    }
   ],
   "source": [
    "predictions = rf.predict(test_input)\n",
    "print(\"Results for split test\")\n",
    "\n",
    "print(f\"  MSE: {mean_squared_error(test_labels, predictions)}\")\n",
    "print(f\"  R2:  {r2_score(test_labels, predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 152 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=24)]: Done 402 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=24)]: Done 752 tasks      | elapsed:    1.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for split validate\n",
      "  MSE: 0.6187925744126135\n",
      "  R2:  0.10348448464320137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=24)]: Done 1000 out of 1000 | elapsed:    1.5s finished\n"
     ]
    }
   ],
   "source": [
    "predictions = rf.predict(val_input)\n",
    "#predictions = [round(x) for x in predictions]\n",
    "print(\"Results for split validate\")\n",
    "print(f\"  MSE: {mean_squared_error(val_labels, predictions)}\")\n",
    "print(f\"  R2:  {r2_score(val_labels, predictions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a simple Linear Regression for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(train_input,np.ravel(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for split train\n",
      "  MSE: 0.6946566961738246\n",
      "  R2:  0.033733536064246006\n",
      "Results for split test\n",
      "  MSE: 0.6130907725088902\n",
      "  R2:  0.0256224263803555\n",
      "Results for split val\n",
      "  MSE: 0.684452169995276\n",
      "  R2:  0.008355925242198636\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(train_input)\n",
    "print(\"Results for split train\")\n",
    "print(f\"  MSE: {mean_squared_error(train_labels, predictions)}\")\n",
    "print(f\"  R2:  {r2_score(train_labels, predictions)}\")\n",
    "predictions = model.predict(test_input)\n",
    "print(\"Results for split test\")\n",
    "print(f\"  MSE: {mean_squared_error(test_labels, predictions)}\")\n",
    "print(f\"  R2:  {r2_score(test_labels, predictions)}\")\n",
    "print(\"Results for split val\")\n",
    "predictions = model.predict(val_input)\n",
    "print(f\"  MSE: {mean_squared_error(val_labels, predictions)}\")\n",
    "print(f\"  R2:  {r2_score(val_labels, predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CDCHacks2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
